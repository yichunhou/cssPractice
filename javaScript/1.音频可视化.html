<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>音频可视化</title>
</head>

<body>
  <input id="audioFile" type="file" accept="audio/*" />
  <canvas id="canvas"></canvas>
  <script>
    // const inputFile = document.querySelector("#audioFile");
    // inputFile.onchange = function (event) {
    //   console.log('evet对象：', event.target);
    //   const file = event.target.files[0];
    //   // 1.使用FileReader读取音频文件数据
    //   const reader = new FileReader();
    //   console.log('文件：', file);
    //   reader.readAsArrayBuffer(file);
    //   reader.onload = evt => {
    //     const encodedBuffer = evt.currentTarget.result;
    //     // 2.创建音频对象 AudioContext
    //     const context = new AudioContext();
    //     // 3.解码音频
    //     context.decodeAudioData(encodedBuffer, decodedBuffer => {
    //       console.log('ceshi', encodedBuffer, decodedBuffer);
    //       // 4.利用AudioBufferSourceNode对象存储解码后的音频数据
    //       const dataSource = context.createBufferSource();
    //       dataSource.buffer = decodedBuffer;
    //       dataSource.connect(context.destination);
    //       dataSource.start();
    //     })
    //   }
    // }


    const canvas = document.querySelector("#canvas");
    const inputFile = document.querySelector("#audioFile");

    const canvasWidth = window.innerWidth;
    const canvasHeight = window.innerHeight;
    const canvasContext = canvas.getContext("2d");
    canvas.width = canvasWidth;
    canvas.height = canvasHeight;
    let frequencyData = [],
      bufferLength = 0,
      analyser;

    inputFile.onchange = function (event) {
      const file = event.target.files[0];

      const reader = new FileReader();
      reader.readAsArrayBuffer(file);
      reader.onload = evt => {
        const encodedBuffer = evt.currentTarget.result;
        const context = new AudioContext();
        context.decodeAudioData(encodedBuffer, decodedBuffer => {
          const dataSource = context.createBufferSource();
          dataSource.buffer = decodedBuffer;
          analyser = createAnalyser(context, dataSource);
          bufferLength = analyser.frequencyBinCount;
          frequencyData = new Uint8Array(bufferLength);
          dataSource.start();
          drawBar();
        })
      }

      function createAnalyser(context, dataSource) {
        const analyser = context.createAnalyser();
        analyser.fftSize = 256;
        dataSource.connect(analyser);
        analyser.connect(context.destination);
        return analyser;
      }

      function drawBar() {
        requestAnimationFrame(drawBar);
        analyser.getByteFrequencyData(frequencyData);
        canvasContext.clearRect(0, 0, canvasWidth, canvasHeight);
        let barHeight, barWidth, r, g, b;
        for (let i = 0, x = 0; i < bufferLength; i++) {
          barHeight = frequencyData[i];
          barWidth = canvasWidth / bufferLength * 2;
          r = barHeight + 25 * (i / bufferLength);
          g = 250 * (i / bufferLength);
          b = 50;
          canvasContext.fillStyle = "rgb(" + r + "," + g + "," + b + ")";
          canvasContext.fillRect(x, canvasHeight - barHeight, barWidth, barHeight);
          x += barWidth + 2;
        }
      }
    }
  </script>
</body>

</html>